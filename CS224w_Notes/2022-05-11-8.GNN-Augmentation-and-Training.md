---
categories: CS224w_Notes
---

# GNN framework
计算图不必须和原图中的边和结点完全相同，有各种技术可以用来创建计算图  

## 为什么不使用原图作为计算图
- 特征层面: 图输入可能缺少特征 -> feature augmentation  
- 图结构层面:  
图可能过于稀疏 -> 信息传递效率低 -> add virtual nodes / edges  
图可能过于稠密 -> 信息传递代价过大 -> sample neighbors when doing message passing  
图可能太大 -> 无法将整张计算图放到GPU中训练 -> sample subgraph to compute embeddings  

-> 输入图很难是最优的计算图  

## 图特征增强
1. 有时输入图没有结点特征:  
-> 为每个结点分配一个常数值  
-> 为每个结点赋一个独特的值，如独热码  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141941367.png)  

2. 有些结构不易于GNN学习:  
GNN无法区别不同大小的环(因为这些环的计算图都非常相似)  
-> 可以将结点环的长度也作为一个结点的特征  

在第2节介绍的方法都可以运用于特征增强  

## 图结构增强
### 为图添加虚拟结点/边
在结点和他邻居结点的邻居结点(两跳结点)之间添加虚拟边  
邻接矩阵表示: $$A = A + A^2$$(前面讲到$$A^k$$是结点i -> j距离为k的路径数)  
ex. 对于只有authors和papers组成的bipartite graph，为两跳结点添加边表示在合作同一篇论文的两个作者之间添加边  

对于稀疏图:  
可能需要传递信息的两个结点距离非常远  
-> 添加一个连接所有结点的虚拟结点，则所有结点之间的距离都减小为2  
这种方式改善了在稀疏图中传递消息  

### 抽样邻居结点
有的结点的邻居结点太多了  
-> 随机抽样: 可能导致与结点有很重要关系的邻居结点被忽略  
-> 每次抽样不同的邻居  
-> 我们希望抽样后，计算图的表现和没有抽样时的表现差不多  


# training GNN
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141941402.png)  

## prediction head
### node level prediction
可以直接使用node embedding预测  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141941168.png)  

### edge level prediction
使用一对node embedding预测  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141942152.png)  

options for $$Head_{edge}(h_u^{(L)}, h_v^{(L)})$$:  
1. 连接 + 线性变换  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141942755.png)  
这里的Linear(·)用于将2d维的向量转换为k维向量(用于判断边属于k类中的那一类)  
2. 点乘  
连接预测(只预测边是否存在): $$\hat{y}_{uv} = (h_u^{(L)})^Th_v^{(L)}$$ (结果$$\hat{y}_{uv}$$是一个常数)  
分类预测(预测边属于k类中的那一类):  
$$
\hat{y}_{uv}^{(1)} = (h_u^{(L)})^TW^{(1)}h_v^{(L)} \\
... \\
\hat{y}_{uv}^{(k)} = (h_u^{(L)})^TW^{(k)}h_v^{(L)} \\
\hat{y}_{uv} = Concat(\hat{y}_{uv}^{(1)}, ..., \hat{y}_{uv}^{(k)}) \in R^k
$$

### graph level prediction
需要用到图中所有结点的node embedding进行预测  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141942303.png)  

options for $$Head_{graph}(\{ h_v^{(L)} \in R^d, \forall v \in G \})$$:  
1. global mean pooling:  
$$\hat{y}_G = Mean(\{ h_v^{(L)} \in R^d, \forall v \in G \})$$  
2. global max pooling:  
$$\hat{y}_G = Max(\{ h_v^{(L)} \in R^d, \forall v \in G \})$$  
3. global sum pooling:  
$$\hat{y}_G = Sum(\{ h_v^{(L)} \in R^d, \forall v \in G \})$$  
- 这些在小样本数据中有很好的表现   

-> 有时区别很大的两个embedding vector可能经过global pooling后变的非常相似 -> 通过层次聚合node embedding解决  
先将所有的node embedding分为非常多块，每块先进行聚合  
然后在得到的所有聚合中再分块，再聚合 -> 重复上述操作直到聚合到只剩下一个vector / number  
-> 如何将node embedding分块:  
1. 社区检测/图分割算法  
2. 建立两个GNN:  
一个用于计算结点的node embedding  
一个用于计算结点应该属于那个聚类  

## predictions and labels
### supervised / unsupervised
supervised: label来自外部(如通过分子结构预测药物的相似性)  
unsupervised: 由图自己生成信号(如预测两结点之间是否存在边)  

## loss function
classification / regression: label是离散值/连续值  
区别在于使用不同的损失函数和评价方法  

### classification loss
-> cross entropy (CE) is a very common loss function in classification  
k-way prediction for i-th data point:  
$$ CE(y^{(i)}, \hat{y}^{(i)}) = - \sum_{j = 1}^K y_j^{(i)} \log (\hat{y}_j^{(i)}) $$
total loss over all N training examples:  
$$Loss = \sum_{i = 1}^N CE(y^{(i)}, \hat{y}^{(i)})$$

### regression loss
-> Mean Squared Error (MSE)  
k-way prediction for i-th data point:  
$$MSE(y^{(i)}, \hat{y}^{(i)}) = \sum_{j = 1}^K (y^{(i)}_j - \hat{y}^{(i)}_j)^2$$
total loss over all N training examples:  
$$Loss = \sum_{i = 1}^N MSE(y^{(i)}, \hat{y}^{(i)})$$

## evaluation metrics
### regression
- Root mean square error (RMSE)  
$$\sqrt{\sum_{i = 1}^N \frac{(y^{(i)} - \hat{y}^{(i)})^2}{N}}$$
- Mean absolute error (MAE)  
$$ \frac{\sum_{i = 1}^N |y^{(i)} - \hat{y}^{(i)}|}{N} $$

### classification
- Multi-class classification  
$$\frac{预测正确的个数}{N}$$
这种方法适合于正样本和负样本比较平均的情况，因为这种情况下，模型的预测值会向正样本/负样本倾斜，则这个模型本身是有问题的，但是这种评价方法依然会给出很高的准确度   
- binary classification  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141943055.png)  
Accuracy: $$\frac{TP + TN}{TP + TN + FP + FN} = \frac{TP + TN}{|Dataset|}$$ 预测的所有值中有多少是正确的    
Precision(P): $$\frac{TP}{TP + FP}$$ 预测的真值中有多少是正确的   
Recall: $$\frac{TP}{TP + FN}$$ 在所有本来是真值中，有多少被正确预测了   
F1-Score: $$\frac{2P * R}{P + R}$$ 精度率和召回率的调和平均值   
ROC Curve:  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141943337.png)  
其中$$TPR = Recall = \frac{TP}{TP + FN}, FPR = \frac{FP}{FP + TN}$$  
ROC图像的特点:  
如果是一个随机分类器，则ROC曲线应为图中的灰色虚线  
如果是一个非常好的分类器，则ROC曲线应该是非常快的达到最高点然后保持在最高点不变   
ROC AUC: ROC曲线的下面积  

## 如何将数据集分为训练集/验证集/测试集
fix split: 一次性将数据集分为训练集/验证集和测试集  
在图神经网络中，不能保证测试集一定是独立的，可能有信息会从训练集和验证集泄露到测试集  
random split: 随机切分数据集，应用多次随机切分后计算结果的平均值  
-> 因为图中的结点都存在相互联系，在这种情况下，各个集合中的结点其实是有关系的  
### transductive setting
适用于只有一张图的情况  
不对图的结构进行拆分，只是将结点分到三个集合中  
在training过程中，虽然embedding时使用图中的全部结点，但是只预测训练集中存在的结点的label  
在validation过程中，同理，虽然使用整张图进行embedding，但是只使用验证集中的结点进行验证  
-> 只适用于结点和边预测任务中  

### inductive setting
适用于有多张图的情况(有一张图的情况也适用)  
如果只有一张图: 删除不同集合之间连接的边，从而得到三个相互独立的图   
如果有多张图: 将不同的图分到各个训练集中  
-> 不适用于只有一张图且是一张小型的图   

### 对边进行预测
将一些边隐藏，然后预测这些边是否存在  
-> 图中的边被分为两种，一种是需要传递信息的边；另一种是用来训练的边  
- step1: 将两种边放到原图中  
这里用来训练的边不应该被放在GNN当中  

- step2: 将图分到三种集合当中  
1. 使用inductive setting，将不同的图分到不同集合后划分传递信息的边和用来训练的边  
2. 使用transductive setting，将边划分为4种，消息传递的边，用来给training预测的边，用来给validation预测的边，用来给test预测的边
-> 在训练时使用消息传递的边训练，并用给training预测的边预测 ...  
这种行为可以被理解为: 随着时间的推移，图上的边会逐逐渐变多  

