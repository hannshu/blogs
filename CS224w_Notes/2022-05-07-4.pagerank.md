---
categories: CS224w_Notes
---

# pagerank
graph -> matrix  
node: web pages, edges: hyperlinks  
将网络表示成为一个有向图  
goal: compute the importance of a web page  
-> more link more importance  
-> importance web pages' in link is importance(recursive)  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141929622.png)  
importance: 通过其他网站指向你所得到(通过out link得到) -> 将你的important平均分给每个指向(通过out link分散给其他网站)  
A page is important if it is pointed to by other important pages  
重要性计算公式: $$r_j = \sum_{i -> j} \frac{r_i}{d_i}$$ (网站的重要性通过 指向其的网站的重要性 以及 该网站的链接数 所确定)   
-> 通过每个网站的重要性公式，再添加一个对所有重要性总和的约束，即可通过方程求解的方式计算出所有网站的重要性(时间复杂度太高)  

## matrix formulation
- 随机邻接矩阵M(n * n):  
如果网站j有$$d_j$$个out link，j -> i，则M[i][j] = 1/$$d_j$$  
M每列表示一个网站的所有out link(每列上的数之和为1)  

- rank vector r:  
$$ r_i $$表示第i个页面的重要性  
-> r中所有元素之和为1  

=> r = M * r  
结合随机游走: 这里即假设有人随机的点击网页上的out link来游走，设其t时刻每个网站被访问的概率为p(t)，则可以得到p(t + 1) = M * p(t) -> 不断重复计算这个公式，可以得到一个稳定的向量p  
结合katz index: katz index通过不断计算邻接矩阵的幂来获得i -> j距离为k时的路径数，在这里计算r = M * M * ... * M * r来使r趋于稳定  
结合Engienvector centrality: 这里r就是特征值为1时随机邻接矩阵M的特征向量(本征向量principal eigenvector)  

## compute vector r
先为r设置随机值，然后不断计算r = M * r，直到收敛 $$\sum_i |r_i^{t + 1} - r_i^t|_1 < \varepsilon$$ -> power iteration(大约50次就可以收敛)    
-> 这里可以通过power iteration只计算r中的一些点，得到这些点的重要性后，再通过一次r = M * r得到整个r的值  

### spider trap
可能有网站指向自己：导致在随机游走时被困住，导致其吸收指向这个网站的其他网站的重要性  
(因为从其他网站走到这个网站后会不断重复这个网站)  

-> 更改随机游走的规则，每次随机游走不止会游走到其他out link的网站上，还可能会跳转到其他网站上  
设置一个概率ß，有ß到概率继续随机游走，有(1 - ß)的概率跳转到一个随机页面上(一般情况下ß设置在0.8 - 0.9)  

### dead end
可能有的网站不存在out link：导致随机游走时下一次没有地方可去，导致最终算得的重要性极小  

这主要是因为这个网站的随机邻接矩阵不符合规则，即M[i]这一列的和不为1  
来到这个网站后直接随机跳转到其他网站上，即M[i]这一列全部设置一个相同的概率1 / d(d为网络中结点的个数) -> 从这个点跳转到网络中任意一点的概率都相同  

最终形式:  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141930472.png)  
the google matrix G: $$G = \beta * M + (1 - \beta) * [\frac{1}{N}]_{N * N}$$  
(其中N为网络中的结点个数)  

## personalized pagerank
在随机游走时，每次跳转只会跳转到一个结点集S中  
(这里只需要修改随机邻接矩阵及可以实现，将存在于S中的点的概率调整为非0，其余结点调整为0)  

## random walks with restart:  
在随机游走时，每次跳转只能跳转回最开始的结点  
![](https://cdn.jsdelivr.net/gh/hannshu/imgs/img/202301141930637.png)  
每次只有两种选择: 去下一个结点，或者是回到初始结点中(跳转的概率为ALPHA)  
最终产生的概率分布就可以认为是受初始结点影响的概率分布  
(与上面类似，只有开始点为1，其余点均为0)  

# matrix factorization and node embeddings
## matrix factorization
random walk model can be formulated as a matrix factorization.  
Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec, WSDM 18

## limitation of node embedding 
1. 无法获取不在训练集中的节点的嵌入  
新增结点是需要重新训练整个矩阵  

2. 无法捕捉到结构相似性  
模型考虑到的更多是结点的身份信息，而非其局部的结构信息  
(可以通过anonymous walk embedding解决这个问题)  

3. 不能利用节点、边和图的特征  
-> 图神经网络
